---
title: "Projekt Eksploracja Danych"
author: "Michał Szulierz"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
toc-title: Spis treści
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

<head>
  <style>
    body {
      font-size: 18px;
    }
  </style>
</head>


```{r,message=FALSE,warning=FALSE}
library(tidyverse)
library(ggplot2)
library(rio)
library(PerformanceAnalytics)
library(tidymodels)
library(class)
library(pROC)
library(ISLR)
library(rpart)
library(rpart.plot)
library(caret)
library(kableExtra)
library(reshape)
library(ROCR)
library(tidymodels)
library(randomForest)
library(caTools)
library(e1071)
library(MASS)
```

```{r,results='hide',message=FALSE,warning=FALSE}
dane <- read.csv("C:\\Users\\48502\\Desktop\\Baza\\IAD6Sem\\EksploracjaDanych\\Projekt\\heart.csv")
head(dane)
colnames(dane) <- c("Wiek","Plec","Typ_bólu","Ciśnienie_krwi","Cholesterol","Cukier",
                    "Wynik_EKG","Tętno","Dławica_Piersiowa","spadek_odcinka_ST",
                    "nachylenie","Liczba_Naczyń","defekt","ChorobaSerca")
head(dane)
str(dane)
summary(dane)
dane$Plec <- factor(dane$Plec)
dane$Typ_bólu <- factor(dane$Typ_bólu)
dane$Wynik_EKG <- factor(dane$Wynik_EKG)
dane$Dławica_Piersiowa <- factor(dane$Dławica_Piersiowa)
dane$nachylenie <- factor(dane$nachylenie)
dane$defekt <- factor(dane$defekt)
dane$ChorobaSerca <- as.factor(dane$ChorobaSerca)
dane <- dane %>% mutate_at(c(2,3,6,7,9,11,12,13,14), as.factor)
dane <- dane%>% mutate_if(is.integer,as.numeric)
```

## **Heart Attack Analysis & Prediction** 

### **Cel Projektu**

Celem projektu jest przeprowadzenie analizy zbioru `Heart Attack Analysis & Prediction Dataset` ,stworzenie wielu modeli które będą przewidywać wystąpienie Choroby Serca u pacjenta i na końcu porównać je wszystkie i wybrać najlepszy.

### **Dane** 

Zbiór danych `Heart Attack Analysis & Prediction Dataset` zawiera dane dotyczące pacjentów, którzy zostali poddani badaniom diagnostycznym związanym z chorobą serca.

1. <big>**Wiek**</big> - wiek pacjenta w latach
2. <big>**Plec**</big> - płeć pacjenta (0 - kobieta, 1 - mężczyzna)
3. <big>**Typ_bólu**</big> - typ bólu w klatce piersiowej (0 - typowa dławica piersiowa, 1 - nietypowa dławica piersiowa, 2 - ból niezwiązany z dławicą, 3 - typ bezobjawowy)
4. <big>**Ciśnienie_krwi**</big> - ciśnienie krwi w spoczynku (w mm Hg)
5. <big>**Cholesteror**</big> - poziom cholesterolu w surowicy (w mg/dl)
6. <big>**Cukier**</big> - poziom cukru we krwi na czczo (> 120 mg/dl = 1, 0 w przeciwnym razie)
7. <big>**Wynik_EKG**</big> - wynik elektrokardiogramu podczas spoczynku (0 - norma, 1 - odchylenie ST-T, 2 - hipertrofia lewej komory)
8. <big>**Tętno**</big> - maksymalne osiągnięte tętno
9. <big>**Dławica_Piersiowa**</big> - dławica piersiowa spowodowana wysiłkiem (0 - nie, 1 - tak)
10. <big>**spadek_odcinka_ST**</big> - spadek odcinka ST wywołany wysiłkiem fizycznym względem spoczynku
11. <big>**Nachylenie**</big> - nachylenie odcinka ST podczas wysiłku (0 - brak, 1 - nachylenie w górę, 2 - nachylenie w dół)
12. <big>**Liczba_Naczyń**</big> - liczba głównych naczyń krwionośnych (0-3) zabarwionych podczas fluoroskopii
13. <big>**defekt**</big> - rodzaj defektu (0 - brak, 1 - odwrócony, 2 - normalny, 3 - odwrócony z niedoborem)
14. <big>**ChorobaSerca**</big> - wartość docelowa, określająca obecność choroby serca (0-mniejsza szansa na atak serca, 1-większa szansa na atak serca)

```{r}
dane %>% 
  kbl() %>% 
  kable_styling(bootstrap_options = c("striped","hover")) %>% 
  scroll_box(width = "100%" ,height = "500px")
```

### **Braki Danych** 
```{r,message=FALSE,warning=FALSE}
sum(is.na(dane))
```
Braki Danych nie występują

## **Wizualizacje** 

### **Rozkład Wieku**

```{r}
dane%>%
  ggplot(aes(x=Wiek))+
  geom_histogram(bins=12,color="white",fill="blue")+
  labs(title = "Wiek badanych osób", y = "Liczba wystąpień", x = "Wiek")+
  theme_bw()
```

Widzimy delikatną lewostronną asymetrię, jeżeli chodzi o wiek badanych osób. Oznacza to że pacjenci są starsi.

### **Rozkład Tętna**

```{r}
dane%>%
  ggplot(aes(x=Tętno))+
  geom_histogram(bins=12,color="white",fill="grey")+
  labs(title = "Tętno badanych osób", y = "Liczba wystąpień", x = "Tętno")+
  theme_bw()
```

Widzimy zdecydowaną lewostronną asymetrię jeżeli chodzi o tętno badanych osób. Oznacza to, że pacjenci mają podwyższone tętno.

### **Rozkład Ciśnienia Krwi**

```{r}
dane%>%
  ggplot(aes(x=Ciśnienie_krwi))+
  geom_histogram(bins=12,color="white",fill="red")+
  labs(title = "Ciśnienie krwi badanych osób", y = "Liczba wystąpień", x = "Ciśnienie krwi")+
  theme_bw()
```

Widzimy zdecydowaną prawostronną asymetrię jeżeli chodzi o Ciśnienie krwi badanych osób. Oznacza to że pacjenci nie cechują się nadmiernie podwyższonym ciśnieniem.

### **Płeć Pacjentów** 
```{r,results='hide',message=FALSE,warning=FALSE,echo=FALSE}
dane %>%
  ggplot(aes(x=Plec, fill=Plec)) +
  geom_bar() +
  labs(title = "Liczba badanych osób", y = "Liczba", x = "Płeć")+
  scale_x_discrete(labels = c("F", "M"), 
                   breaks = c("0", "1"))+
  scale_fill_manual(values = c("0"="deeppink", "1"="dodgerblue"),labels=c("F","M")) +
  geom_text(stat='count', aes(label=..count..), position=position_stack(vjust=0.5)) +
  theme_bw()
```

W Zbiorze danych mamy 96 kobiet oraz 207 mężczyzn, oznacza to że zbiór jest nie zbalansowany pod względem płci.

### **Poziom Cholesterolu** 
```{r,results='hide',message=FALSE,warning=FALSE,echo=FALSE}
dane %>%
  group_by(Wiek) %>%
  summarize(mean_chol = mean(Cholesterol, na.rm = TRUE)) %>%
  ggplot(aes(x = Wiek, y = mean_chol, fill = mean_chol)) +
  geom_bar(stat = "identity") +
  labs(title = "Związek między wiekiem a poziomem cholesterolu", y = "Średni poziom cholesterolu", x = "Wiek") +
  theme_bw() +
  scale_fill_gradient(low="powderblue",high="firebrick")+
  scale_x_continuous(breaks = seq(20, 80, 5))
```

Na wykresie widzimy że wyższy poziom cholesterolu wystepuje u ludzi starszych.

```{r}
chlg1 <- dane %>%
  filter(Cholesterol < 200)%>%
  summarise(Liczba_Osob=n())
chlg2 <- dane %>%
  filter(Cholesterol > 200 & Cholesterol<250)%>%
  summarise(Liczba_Osob=n())
chlg3 <- dane %>%
  filter(Cholesterol > 250)%>%
  summarise(Liczba_Osob=n())
chl <- data.frame(
  grupa = c("Cholesterol ponizej 200","Cholesteror między 200 a 250","Cholesteror powyżej 250"),
  Liczba_Osob = c(chlg1$Liczba_Osob, chlg2$Liczba_Osob,chlg3$Liczba_Osob)
)

ggplot(data = chl, aes(x = grupa, y = Liczba_Osob)) + 
  geom_col(fill=c("#E69F00", "#8B5547","#8B0000")) +
  labs(title = "Poziom cholesterolu u pacjentów",
       y = "Liczba osób", x = "") +
   geom_text(aes(label = Liczba_Osob), position = position_dodge(width = 0.6),
             vjust = -0.5)+
  theme_bw()
```

Cholesterol całkowity u zdrowego człowieka nie powinien przekraczać `200 mg/dl`. Jedynie u 50 pacjentów Cholesterol jest w normie. U 123 pacjentów Cholesterol jest na poziomie podwyższonym. 126 pacjentów ma Cholesterol znacznie podwyższony.

### **Średnia wieku** 
```{r}
dane %>%
  group_by(ChorobaSerca) %>%
  summarize(mean_wiek = mean(Wiek)) %>%
  ggplot(aes(x=ChorobaSerca, y=mean_wiek, fill=factor(ChorobaSerca))) +
  geom_col(position="dodge") +
  geom_text(aes(label=round(mean_wiek,1)), position=position_dodge(width=0.9), vjust=-0.5) +
  labs(title="Średni wiek pacjentów w zależności od obecności choroby serca",
       x="Obecność choroby serca", y="Średni wiek") +
  scale_x_discrete(labels = c("Brak", "Obecność"), 
                 breaks = c("0", "1"))+
  scale_fill_manual(values=c("#999999", "#E69F00"),labels=c("Brak","Obecność"),name="Choroba Serca") +
  theme_bw()
```

Wykres przedstawia średni wiek pacjentów w zależności od obecności choroby serca. Średni wiek pacjetnów nie posiadających choroby serca wynosi `56.6` a pacjentów posiadających chorobę serca `52.5`.

### **Typ bólu oraz Ciśnienie Krwi** 
```{r}
ggplot(dane, aes(x=factor(Typ_bólu), y=Ciśnienie_krwi, fill=factor(Typ_bólu))) +
  geom_boxplot() +
  labs(title="Rozkład wartości ciśnienia krwi w zależności od typu bólu w klatce piersiowej",
       x="Typ bólu w klatce piersiowej", y="Ciśnienie krwi") +
  scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9", "#009E73")) +
  theme_bw()
```

Wykres przedstawia rozkład wartości ciśnienia krwi w zależności od typu bólu w klatce piersiowej.

### **Obecność Choroby serca a tętno** 
```{r}
ggplot(dane, aes(x=Wiek, y=Tętno, color=factor(ChorobaSerca))) +
  geom_point(alpha=0.5) +
  labs(title="Związek między wiekiem a tętnem pacjentów",
       x="Wiek (lata)", y="Tętno (uderzenia na minutę)", color="Obecność choroby serca") +
  scale_color_manual(values=c("#999999", "#E69F00")) +
  theme_bw()
```

Wykres przedstawia związek między wiekiem a tętnem pacjentów, a dodatkowo oznacza, czy pacjenci mieli obecność choroby serca. Kolor punktów na wykresie odpowiada kategorii obecności choroby serca. Punkt o kolorze szarym oznacza brak choroby serca, a punkt o kolorze pomarańczowym oznacza obecność choroby serca.

## **Modelowanie**

W tym etapie przejdziemy do tworzenia modeli, które będą tworzyć predykcję odnośnie pacjentów którzy są zdrowi oraz chorzy. Modele bedą porównywane za pomocą miar `Accuracy` oraz `AUC`. Sprośród 9 modeli na końcu wybierzemy najlepszy czyli taki który ma najlepsze współczynniki dla miar czyli najlepiej przewiduje stan pacjenta.

`Accuracy` – dokładność klasyfikatora. Stosunek ilości dobrze rozpoznanych obiektów do ilości wszystkich obiektów.

Metryka oceny `AUC`(Area under Curve) jest obliczana jako obszar pod krzywą ROC (ocena poprawności klasyfikatora) i jest skalarną reprezentacją oczekiwanej wydajności klasyfikatora. Współczynnik AUC zawsze ma wartość z przedziału od 0 do 1, przy czym wyższe wartości reprezentują lepszy klasyfikator.

### **Drzewo decyzyjne** 

Drzewo decyzyjne to metoda uczenia maszynowego służąca do tworzenia modeli predykcyjnych lub klasyfikacyjnych. Opiera się na hierarchicznej strukturze węzłów i krawędzi, które reprezentują decyzje i zależności między zmiennymi objaśniającymi.

```{r,results='hide'}
set.seed(2023)

podzial <- initial_split(dane,prop=0.7,strata=ChorobaSerca)
trenowane <- training(podzial)
testowane <- testing(podzial)

crval <- vfold_cv(trenowane, v = 10,repeats = 5)
```


```{r,results='hide',message=FALSE,warning=FALSE,echo=FALSE}
set.seed(2023)
mod.rpart <- rpart(ChorobaSerca~., data = trenowane, 
                   control = rpart.control(minsplit = 10,
                                           minbucket = 10,
                                           maxdepth = 3))

summary(mod.rpart)
rpart.plot(mod.rpart)
pred.prob <- predict(mod.rpart,newdata=testowane)
pred.prob[10:20]
```

Drzewo decyzyjne wylicza prawdopodobieństwo wystąpienia Choroby serca w zależności od wielu czynników. W tym przypadku jeżeli pacjent ma typ `defektu` 0,1 lub 3 to jeżeli `typ bólu` wynosi 0(typowa dławica piersiowa) mamy 29% na brak Choroby Serca w innym wypadku jeżeli `nachylenie` wynosi 1 to mamy 10% szans na brak Choroy Serca i 6% na wystąpienie Choroby Serca.

```{r,results='hide',message=FALSE,warning=FALSE,echo=FALSE}
pred.class <- predict(mod.rpart, newdata = testowane, type = "class")
pred.class
tab <- table(predykcja = pred.class, obserwacja = testowane$ChorobaSerca)
tab
accdc <- sum(diag(tab)/sum(tab))
accdc

ggplot(data = as.data.frame(tab), aes(y = predykcja, x = obserwacja, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq),size=10,color="black") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(title = "Macierz Pomyłek",  x = "Prawdziwa klasa", y = "Przewidywana klasa") +
  theme_bw()
```

- 36 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 6 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 10 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 40 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r,results='hide',message=FALSE,warning=FALSE,echo=FALSE}
pred <- prediction(pred.prob[,2], testowane$ChorobaSerca)

perf_dt <- performance(pred, measure = "tpr", x.measure = "fpr")
auc_dt <- performance(pred, measure = "auc")@y.values[[1]]

ggplot(data = data.frame(x = perf_dt@x.values[[1]], y = perf_dt@y.values[[1]]),
       aes(x = x, y = y)) +
  geom_line() +
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_dt, 2)))+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi: ``r round(accdc,2)``, miara `AUC`=``r round(auc_dt,2)``.

Drzewo Decyzyjne w zadowalający sposób wykonuje klasyfikacje. Zobaczymy jak wyjdzie reszta modeli.

### **Regresja Logistyczna** 

Regresja logistyczna to popularna metoda uczenia maszynowego stosowana w zadaniach klasyfikacji binarnej. Polega na szukaniu liniowej relacji między zmiennymi niezależnymi, a prawdopodobieństwem przynależności obserwacji do jednej z dwóch klas. 

```{r,message=FALSE,warning=FALSE,echo=FALSE}
set.seed(2023)
model_reglog <- glm(ChorobaSerca ~ ., data = trenowane, family = binomial())

pred <- predict(model_reglog, newdata = testowane, type = "response")

pred_binary <- ifelse(pred >= 0.6, 1, 0)

pred_factor <- factor(pred_binary, levels = c(0, 1))
actual_factor <- factor(testowane$ChorobaSerca, levels = c(0, 1))

tab <- table(pred_factor, actual_factor)

conf_mat <- table(pred_factor, actual_factor)
acclogreg <- sum(diag(conf_mat)/sum(conf_mat))

df <- as.data.frame.matrix(conf_mat)
df$pred_factor <- rownames(df)
df <- tidyr::pivot_longer(df, cols = c("0", "1"), names_to = "actual_factor", values_to = "freq")

ggplot(df, aes(x = actual_factor, y = pred_factor, fill = freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = freq),size=10,color="black") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(x = "Prawdziwa klasa", y = "Przewidywana klasa", title = "Macierz Pomyłek") +
  theme_bw()
```

- 34 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 8 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 8 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 42 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).


```{r}
pred_log <- predict(model_reglog, newdata = testowane, type = "response")

pred_binary <- prediction(pred_log, actual_factor)

perf_log <- performance(pred_binary, measure = "tpr", x.measure = "fpr")
auc_rl <- unlist(performance(pred_binary, measure = "auc")@y.values)

roc_curve <- performance(pred_binary, measure = "tpr", x.measure = "fpr")
ggplot() +
  geom_line(data = data.frame(x = roc_curve@x.values[[1]], y = roc_curve@y.values[[1]]), 
            aes(x = x, y = y)) +
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych") +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_rl, 2)))+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(acclogreg,2)``, miara `AUC`=``r round(auc_rl,2)``.

Regresja Logistyczna dała lepsze wyniki niż Drzewo Decyzyjne dlatego można podejrzewać że będzie jednym z lepszych modeli.

### **Metoda `k` najbliższych sąsiadów** 

Metoda k najbliższych sąsiadów to popularna metoda uczenia maszynowego stosowana w zadaniach klasyfikacji i regresji. Algorytm polega na szukaniu k najbliższych punktów treningowych dla danej próbki testowanej i wybieraniu najczęstszej lub średniej wartości etykiet dla tych sąsiadów.

```{r}
set.seed(2023)
acc <- function(pred, obs){
    tab <- table(pred,obs)
    acc <- sum(diag(prop.table(tab)))
    acc
}

1:20 %>% 
    map(~knn3(ChorobaSerca~., data = trenowane, k = .x)) %>% 
    map(~predict(.x, newdata = testowane, type = "class")) %>% 
    map_dbl(~acc(pred = .x, obs = testowane$ChorobaSerca)) %>% 
    tibble(k = 1:length(.), acc=.) %>% 
    ggplot(aes(k, acc))+
    geom_line()
```

Z wykresu widać że najlepsza liczba sąsiadów wynosi 4 oraz 8. Wybór `k=4` będzie najbardziej optymalny.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
set.seed(2023)

modelknn <- knn3(ChorobaSerca~.,data=trenowane,k=4)
pred_kn <- predict(modelknn,newdata = testowane,type="class")
macpom <- table(pred_kn,testowane$ChorobaSerca)
knnacc <- sum(diag(macpom)/sum(macpom))
macpomdf <- as.data.frame(macpom)

ggplot(data = macpomdf, aes(y = pred_kn, x = Var2, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq),size=10,color="black") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(title = "Macierz Pomyłek",  x = "Prawdziwa klasa", y = "Przewidywana klasa") +
  theme_bw()
```

- 23 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 19 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 14 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 36 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
pred1_knn <- prediction(as.numeric(pred_kn),testowane$ChorobaSerca)

perf_knn <- performance(pred1_knn,measure = "tpr",x.measure = "fpr")

roc_knn <- roc(as.numeric(pred_kn),as.numeric(testowane$ChorobaSerca))
roc_knn_df <- data.frame(
  specificity=roc_knn$specificities,
  sensitivity=roc_knn$sensitivities
)
auc_knn <- roc_knn$auc

ggplot(data = roc_knn_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_knn, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(knnacc,2)``, miara `AUC`=``r round(auc_knn,2)``.

Metoda `k` najbliższych sąsiadów słabo się sprawdza w tym zadaniu, dlatego będzie to jeden z gorszych modeli. 

### **Las Losowy** 

Las losowy to popularny algorytm uczenia maszynowego, który polega na budowaniu wielu drzew decyzyjnych na podstawie losowych podzbiorów danych treningowych i cech. Następnie, dla każdej nowej próbki algorytm stosuje każde z drzew decyzyjnych i wybiera najczęściej pojawiającą się klasę lub średnią wartość prognozy jako wynik. Las losowy jest wydajny i ma wysoką skuteczność w klasyfikacji i regresji, a także może być stosowany do redukcji wymiarowości i wykrywania ważnych cech danych.

```{r}
set.seed(2023)

rf_spec <- rand_forest() %>%
  set_mode("classification") %>%
  set_engine("ranger") #ustawiamy silnik lasu losowego

rf_wf <- workflow() %>%
  add_formula(ChorobaSerca ~ .) %>%
  add_model(rf_spec)

rf_fit <- rf_wf %>%
  fit(data = trenowane)

rf_results <- rf_fit %>%
  predict(new_data = testowane)

conf_mat <- table(rf_results$.pred_class, testowane$ChorobaSerca)
rfacc <- sum(diag(conf_mat)/sum(conf_mat))

conf_table_long <- melt(conf_mat)

ggplot(data = conf_table_long, aes(y = Var.2, x = Var.1, fill = value)) +
  geom_tile() +
  geom_text(aes(label = value),size=10,color="black") +
  scale_fill_gradient(low = "white", high = "red") +
  labs(title = "Macierz Pomyłek",  x = "Prawdziwa klasa", y = "Przewidywana klasa") +
  theme_bw()
```

- 32 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 8 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 10 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 42 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
rf_results1 <- rf_fit %>%
  predict(new_data = testowane,type="prob")

pred_rf <- prediction(rf_results1$.pred_1,testowane$ChorobaSerca)
perf_rf <- performance(pred_rf, measure = "tpr", x.measure = "fpr")

rocrf <- roc(testowane$ChorobaSerca,rf_results1$.pred_1)
rocrfdf <- data.frame(
  specificity=rocrf$specificities,
  sensitivity=rocrf$sensitivities
)
auc_rf <- rocrf$auc

ggplot(data = rocrfdf, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_rf, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(rfacc,2)``, miara `AUC`=``r round(auc_rf,2)``.

Las Losowy nie podał lepszych wyników niż Regresja Logistyczna.

### **Klasyfikator Bayesowski** 

Klasyfikator bayesowski to algorytm uczenia maszynowego, który opiera się na twierdzeniu Bayesa $P \left(A|B\right)=\frac{P\left(B|A\right)\cdot P \left(A\right)}{P \left(B \right)}$ i służy do przewidywania przynależności obiektu do jednej z kilku klas na podstawie cech obiektu. Wykorzystuje wiedzę a priori o danych oraz prawdopodobieństwa warunkowe, aby dokonać klasyfikacji.

```{r}
set.seed(2023)

model_nb <- naiveBayes(ChorobaSerca ~ ., data = trenowane)

predykcja_nb <- predict(model_nb, newdata = testowane)

wyniki_nb <- table(predykcja_nb, testowane$ChorobaSerca)
acc_nb <- sum(diag(wyniki_nb))/sum(wyniki_nb)

df <- data.frame(
  x = rep(colnames(tab), each = ncol(tab)),
  y = rep(rownames(tab), ncol(tab)),
  value = as.vector(tab)
)

ggplot(df, aes(x = x, y = y, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "red") +
    geom_text(aes(label = value),size=10, color = "black") +
  labs(title = "Macierz pomyłek", x = "Prawdziwa klasa", y = "Przewidywana klasa")+
  theme_bw()
```

- 34 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 8 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 8 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 42 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
predykcja_nb <- predict(model_nb, newdata = testowane, type = "raw")

auc_nb <- performance(prediction(predykcja_nb[, 2], testowane$ChorobaSerca), "auc")@y.values[[1]]

pred_roc <- prediction(predykcja_nb[, 2], testowane$ChorobaSerca)
perf_nb <- performance(pred_roc, "tpr", "fpr")
df_roc <- data.frame(x = perf_nb@x.values[[1]], y = perf_nb@y.values[[1]])
ggplot(df_roc, aes(x, y)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_nb, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(acc_nb,2)``, miara `AUC`=``r round(auc_nb,2)``.

Klasyfikator Bayesowski możemy zaliczyć do średniej jakości modeli w kontekście tego zadania.

### **Liniowa Analiza Dyskryminatywna** 

Liniowa analiza dyskryminacyjna (ang. Linear Discriminant Analysis, LDA) to metoda statystyczna stosowana do analizy i klasyfikacji danych. Metoda ta służy do znajdowania liniowych kombinacji zmiennych objaśniających, które najlepiej oddzielają różne grupy danych.

```{r}
set.seed(2023)
  
model_lda <- lda(ChorobaSerca ~ ., data = trenowane)
  
predykcja_lda <- predict(model_lda, newdata = testowane)

wyniki_lda <- table(predykcja_lda$class, testowane$ChorobaSerca)
acc_lda <- sum(diag(wyniki_lda))/sum(wyniki_lda)

wyniki_lda_df <- as.data.frame(wyniki_lda)

colnames(wyniki_lda_df) <- c("Predykcja", "Prawdziwe","Freq")

wyniki_lda_df$Predykcja <- as.factor(wyniki_lda_df$Predykcja)
wyniki_lda_df$Prawdziwe <- as.factor(wyniki_lda_df$Prawdziwe)

macierz_konfuzji <- matrix(c(wyniki_lda_df[1,2], wyniki_lda_df[2,2], wyniki_lda_df[1,1], wyniki_lda_df[2,1]), nrow = 2)

ggplot(data = wyniki_lda_df, aes(x = Prawdziwe, y = Predykcja, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), size=10,color = "black") +
  labs(x = "Prawdziwa klasa", y = "Przewidywana klasa",title="Macierz Pomyłek") +
  theme_bw()
```

- 33 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 9 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 4 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 46 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
pred_lda <- prediction(predykcja_lda$posterior[,2], testowane$ChorobaSerca)
auc_lda <- as.numeric(performance(pred_lda, "auc")@y.values)

perf_lda <- performance(pred_lda, measure = "tpr", x.measure = "fpr")
ggplot(data = data.frame(x = perf_lda@x.values[[1]], y = perf_lda@y.values[[1]]), aes(x = x, y = y)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_lda, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(acc_lda,2)``, miara `AUC`=``r round(auc_lda,2)``.

Liniowa Analiza Dyskryminatywna dała lepsze wyniki niż Las Losowy dlatego, z dostępnych modeli naraźie jest najlepszym.

### **Metoda wektorów nośnych** 

SVM to metoda klasyfikacji i regresji, która opiera się na wyznaczeniu hiperpłaszczyzny rozdzielającej dane o różnych klasach lub wartościach docelowych. SVM dąży do maksymalizacji odległości między hiperpłaszczyzną a najbliższymi punktami z każdej klasy. Dzięki temu SVM dobrze radzi sobie z problemami, gdzie istnieją nieliniowe zależności między zmiennymi.

```{r}
set.seed(2023)

svmModel <- svm(ChorobaSerca~.,data=trenowane)
svmPredykcja <- predict(svmModel,testowane[,-14])
svmAcc <- mean(svmPredykcja==testowane[,14])

trueLabels <- testowane[, 14]
confusionMatrix <- table(svmPredykcja, trueLabels)
confmatdf <- as.data.frame(confusionMatrix)

ggplot(data = confmatdf, aes(y = svmPredykcja, x = trueLabels, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), size=10,color = "black") +
  labs(x = "Prawdziwa klasa", y = "Przewidywana klasa",title="Macierz Pomyłek") +
  theme_bw()
```

- 33 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 9 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 9 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 41 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
roc_svm <- roc(as.numeric(svmPredykcja),as.numeric(trueLabels))
roc_svm_df <- data.frame(
  specificity=roc_svm$specificities,
  sensitivity=roc_svm$sensitivities
)
auc_svm <- roc_svm$auc
pred_svm <- prediction(as.numeric(svmPredykcja),testowane$ChorobaSerca)

perf_svm <- performance(pred_svm,measure = "tpr",x.measure = "fpr")

ggplot(data = roc_svm_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_svm, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(svmAcc,2)``, miara `AUC`=``r round(auc_svm,2)``.

Metoda Wektorów Nośnych dała średnie wyniki.

### **Wzmocnienie Gradientu**

Wzmocnienie Gradientu jest metodą zespołową, która łączy wiele słabych modeli w celu stworzenia silnego klasyfikatora. Popularne implementacje to XGBoost, LightGBM i CatBoost.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
set.seed(2023)
library(gbm)

model_gbm <- gbm(ChorobaSerca~.,data=trenowane,distribution = "gaussian",
             n.trees = 100,
             shrinkage = 0.1,
             interaction.depth = 3)

smg <- as.data.frame(summary(model_gbm))
colnames(smg) <- c("Rodzaj","Wpływ")
kable(round(smg[2],3))%>%
  kable_styling()%>%
  column_spec(1,bold=T,color="white",background = "red")
summary_model <- summary(model_gbm)
```

Z powyższego wykresu oraz tabeli widzimy że najmocniejszy wpływ na Chorobe Serce mają zmienne: `defekt`, `Liczba Naczyń`, `Tętno`, `Wiek` oraz `Typ bólu`.

```{r}
pred_gbm <- predict(model_gbm,newdata=testowane)

wyniki_gbm <- confusionMatrix(factor(ifelse(pred_gbm>1.6,"1","0")),testowane$ChorobaSerca)
acc_gbm <- sum(diag(wyniki_gbm$table)/sum(wyniki_gbm$table))
wyniki_gbm_df <- as.data.frame(wyniki_gbm$table)
colnames(wyniki_gbm_df) <- c("Prawdziwe","Predykcja","Freq")

ggplot(data = wyniki_gbm_df, aes(x = Prawdziwe, y = Predykcja, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), size=10,color = "black") +
  labs(x = "Prawdziwa klasa", y = "Przewidywana klasa",title="Macierz Pomyłek") +
  theme_bw()
```

- 35 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 13 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 7 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 37 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
pred1_gbm <- prediction(pred_gbm,testowane$ChorobaSerca)
perf_gbm <- performance(pred1_gbm,measure = "tpr",x.measure = "fpr")

roc_gbm <- roc(testowane$ChorobaSerca,pred_gbm)
roc_gbm_df <- data.frame(
  specificity=roc_gbm$specificities,
  sensitivity=roc_gbm$sensitivities
)
auc_gbm <- roc_gbm$auc

ggplot(data = roc_gbm_df, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_gbm, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(acc_gbm,2)``, miara `AUC`=``r round(auc_gbm,2)``.

Wzmocnienie Gradientu dało średnie wyniki.

### **Sieć Neuronowa**

Sieć neuronowa to model matematyczny, który składa się z połączonych ze sobą neuronów. Sieć neuronowa otrzymuje sygnały wejściowe, wykonuje pewne obliczenia i przesyła sygnał wyjściowy do innych neuronów. Sieci neuronowe są stosowane w wielu dziedzinach, w tym w rozpoznawaniu obrazów, rozpoznawaniu mowy, klasyfikacji danych i przewidywaniu wyników.

```{r}
library(neuralnet)
library(NeuralNetTools)
set.seed(2023)

dane <- dane %>% mutate_at(c(1:13), as.numeric)

podzial <- initial_split(dane,prop=0.7,strata=ChorobaSerca)
trenowane <- training(podzial)
testowane <- testing(podzial)

model_neur <- neuralnet(ChorobaSerca~ ., data=trenowane,hidden=c(8,4),
                    linear.output = FALSE,err.fct = "ce",stepmax = 100000)
plot(model_neur,rep="best")

pred1 <- predict(model_neur,newdata=testowane)
labels1 <- c("0","1")
prediction_label1 <- data.frame(max.col(pred1))%>%
  mutate(pred1=labels1[max.col.pred1.])%>%
  pull()

siec_tab <- table(testowane$ChorobaSerca,prediction_label1)
siec_df <- as.data.frame(siec_tab)

ggplot(data = siec_df, aes(x = Var1, y = prediction_label1, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), size=10,color = "black") +
  labs(x = "Prawdziwa klasa", y = "Przewidywana klasa",title="Macierz Pomyłek") +
  theme_bw()
```

- 23 pacjentów, którzy nie chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako zdrowi (wartość 0).
- 19 pacjentów, którzy nie chorują na chorobę serca, zostało błędnie zidentyfikowanych jako chorzy (wartość 1).
- 10 pacjentów, którzy chorują na chorobę serca, zostało błędnie zidentyfikowanych jako zdrowi (wartość 0).
- 40 pacjentów, którzy chorują na chorobę serca, zostało poprawnie zidentyfikowanych jako chorzy (wartość 1).

```{r}
check1=as.numeric(testowane$ChorobaSerca)==max.col(pred1)
accuracy1=(sum(check1)/nrow(testowane))

roc_neur <- roc(as.numeric(testowane$ChorobaSerca), as.numeric(pred1[, 2]))
auc_neur <- roc_neur$auc

roc_neur_df <- data.frame(
  specificites <- roc_neur$specificities,
  sensitivities <- roc_neur$sensitivities
)

ggplot(data = roc_neur_df, aes(x = 1-specificites, y = sensitivities)) +
  geom_line() +
  annotate("text", x = 0.5, y = 0.3, label = paste("AUC = ", round(auc_neur, 2)))+
  labs(title = "Krzywa ROC", x = "Odsetek fałszywie pozytywnych",
       y = "Odsetek prawdziwie pozytywnych")+
  theme_bw()
```

Poziom dokładności `Accuracy` wynosi ``r round(accuracy1,2)``, miara `AUC`=``r round(auc_neur,2)``.

Śieć Neuronowa dała średnie wyniki.

## **Podsumowanie i Wnioski** 

Z wcześniej utworzonych modeli wybierzemy najlepszy. Możemy to zrobić porównując ze sobą metryki `Accuracy` oraz `AUC`.

```{r}
plot(perf_lda,col="red")
plot(perf_rf,add=TRUE,col="green")
plot(perf_log,add=TRUE,col="orange")
plot(perf_gbm,add=TRUE,col="blue")
plot(perf_nb,add=TRUE,col="purple")
plot(perf_dt,add=TRUE,col="darkblue")
plot(perf_svm,add=TRUE,col="cyan")
plot(perf_knn,add=TRUE,col="darkgreen")

legend("right",legend = c(paste("Linear discriminant analysis: ",round(auc_lda,2)),
                             paste("Random forest: ",round(auc_rf,2)),
                             paste("Logistic regression: ",round(auc_rl,2)),
                             paste("Gradient Boosting: ",round(auc_gbm,2)),
                             paste("Naive Bayes :",round(auc_nb,2)),
                             paste("Decision tree:", round(auc_dt,2)),
                             paste("SVM: ",round(auc_svm,2)),
                             paste("k-nearest neighbors: ", round(auc_knn,2))
                             ),
       col=c("red","green","orange","blue","purple","darkblue","cyan","darkgreen"),lwd=3,cex=0.6)
```

Z powyższego wykresu widzimy że większa ilość wykresów `ROC` się zlewa natomiast można wyróżnić najlepszy którym jest Liniowa Analiza Dyskryminatywna oraz najgorszy którym jest metoda `k` najbliższych sąsiadów.

```{r}
tabelka <- data.frame(Model=c("Liniowa Analiza Dyskryminatywna","Regresja Logistyczna",
                              "Las Losowy","Drzewo Decyzyjne","Naiwny Klasyfikator Bayesa","Wzmocnienie Gradientowe",
                              "Metoda Wektorów Nośnych","Sieć Neuronowa","Metoda k-najblizszych sasiadów"),
                      Accuracy=c(acc_lda,acclogreg,rfacc,accdc,acc_nb,acc_gbm,svmAcc,accuracy1,knnacc),
                      AUC=c(auc_lda,auc_rl,auc_rf,auc_dt,auc_nb,auc_gbm,auc_svm,auc_neur,auc_knn))

kbl(tabelka,digits=3)%>%
  kable_styling()%>%
  column_spec(1,bold=T,color="white",background = "blue")
```

Po przeprowadzeniu analizy danych oraz modelowaniu za pomocą dziewięciu modeli, możemy uznać, że modelem najlepiej radzącym sobie z klasyfikacją pacjentów ze względu na wystąpienie `Choroby Serca`, jest model Liniowej Analizy Dyskryminacyjnej. Osiągną on wyniki, `Accuracy`=`r round(acc_lda,2)` oraz `AUC`=`r round(auc_lda,2)`. Podczas klasyfikacji pomylił się jedynie trzynaście razy, na dziewięćdziesiąt dwa możliwych przypadków.

## **Bibliografia**

<big>1.</big> `https://dax44.github.io/datamining/`

<big>2.</big>`https://dax44.github.io/ModelsValidation/?fbclid=IwAR3VjEcYyvIyIBX31M9Tf2Wsiz4sSkFrvKsnzqkZb2cMh_iRVZlNmuTwBNQ`